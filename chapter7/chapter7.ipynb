{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]]),\n",
       " array([[12, 14, 16, 18],\n",
       "        [20, 22, 24, 26],\n",
       "        [28, 30, 32, 34]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.arange(24).reshape(2, 3, 4)\n",
    "A[0], A.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  1,  2,  3,  0,  0,  0],\n",
       "        [ 0,  4,  5,  6,  7,  0,  0,  0],\n",
       "        [ 0,  8,  9, 10, 11,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0, 12, 13, 14, 15,  0,  0,  0],\n",
       "        [ 0, 16, 17, 18, 19,  0,  0,  0],\n",
       "        [ 0, 20, 21, 22, 23,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.pad\n",
    "np.pad(A, [(0, 0), (2, 1), (1, 3)], mode=\"constant\")  # pad的第二参数传入填充数量(前，后)的控制数组\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       " \n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]]),\n",
       " array([[[ 0,  4,  8],\n",
       "         [ 1,  5,  9],\n",
       "         [ 2,  6, 10],\n",
       "         [ 3,  7, 11]],\n",
       " \n",
       "        [[12, 16, 20],\n",
       "         [13, 17, 21],\n",
       "         [14, 18, 22],\n",
       "         [15, 19, 23]]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.transpose\n",
    "\n",
    "A, A.transpose((0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 3, 7, 7), (10, 3, 7, 7))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# im2col - 理解测试\n",
    "import sys, os\n",
    "sys.path.append(os.path.pardir)\n",
    "from common.util import im2col\n",
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "x2 = np.random.rand(10, 3, 7, 7)\n",
    "x1.shape, x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 75), (90, 75))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "col1.shape, col2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.27690048 0.76475499 0.68128395]\n",
      "   [0.54320895 0.27959686 0.14511859]\n",
      "   [0.64084363 0.08025998 0.21926138]]\n",
      "\n",
      "  [[0.55615633 0.60518473 0.4631491 ]\n",
      "   [0.15524087 0.97385814 0.43232387]\n",
      "   [0.31289063 0.90241461 0.12008861]]\n",
      "\n",
      "  [[0.98854492 0.59147446 0.79659866]\n",
      "   [0.72561051 0.64966604 0.69502992]\n",
      "   [0.22661769 0.41165645 0.89748373]]]]\n",
      "[[[[0.76475499 0.68128395 0.9759702 ]\n",
      "   [0.27959686 0.14511859 0.25309581]\n",
      "   [0.08025998 0.21926138 0.97625881]]\n",
      "\n",
      "  [[0.60518473 0.4631491  0.56542241]\n",
      "   [0.97385814 0.43232387 0.54145095]\n",
      "   [0.90241461 0.12008861 0.11256115]]\n",
      "\n",
      "  [[0.59147446 0.79659866 0.28401414]\n",
      "   [0.64966604 0.69502992 0.31786805]\n",
      "   [0.41165645 0.89748373 0.70215884]]]]\n",
      "[[[[0.68128395 0.9759702  0.27615381]\n",
      "   [0.14511859 0.25309581 0.68592993]\n",
      "   [0.21926138 0.97625881 0.37229464]]\n",
      "\n",
      "  [[0.4631491  0.56542241 0.92087749]\n",
      "   [0.43232387 0.54145095 0.92538702]\n",
      "   [0.12008861 0.11256115 0.25345079]]\n",
      "\n",
      "  [[0.79659866 0.28401414 0.13216539]\n",
      "   [0.69502992 0.31786805 0.28541485]\n",
      "   [0.89748373 0.70215884 0.83384668]]]]\n",
      "[[[[0.9759702  0.27615381 0.69734383]\n",
      "   [0.25309581 0.68592993 0.51459239]\n",
      "   [0.97625881 0.37229464 0.85924442]]\n",
      "\n",
      "  [[0.56542241 0.92087749 0.64043142]\n",
      "   [0.54145095 0.92538702 0.87732365]\n",
      "   [0.11256115 0.25345079 0.17000775]]\n",
      "\n",
      "  [[0.28401414 0.13216539 0.74447842]\n",
      "   [0.31786805 0.28541485 0.83468139]\n",
      "   [0.70215884 0.83384668 0.73522124]]]]\n",
      "[[[[0.27615381 0.69734383 0.80920493]\n",
      "   [0.68592993 0.51459239 0.74913671]\n",
      "   [0.37229464 0.85924442 0.11587277]]\n",
      "\n",
      "  [[0.92087749 0.64043142 0.93879768]\n",
      "   [0.92538702 0.87732365 0.86399078]\n",
      "   [0.25345079 0.17000775 0.33914352]]\n",
      "\n",
      "  [[0.13216539 0.74447842 0.39652742]\n",
      "   [0.28541485 0.83468139 0.20131367]\n",
      "   [0.83384668 0.73522124 0.0291385 ]]]]\n",
      "[[[[0.54320895 0.27959686 0.14511859]\n",
      "   [0.64084363 0.08025998 0.21926138]\n",
      "   [0.41698306 0.24347126 0.38751256]]\n",
      "\n",
      "  [[0.15524087 0.97385814 0.43232387]\n",
      "   [0.31289063 0.90241461 0.12008861]\n",
      "   [0.0584776  0.72047628 0.38497056]]\n",
      "\n",
      "  [[0.72561051 0.64966604 0.69502992]\n",
      "   [0.22661769 0.41165645 0.89748373]\n",
      "   [0.55393726 0.91189093 0.39660921]]]]\n",
      "[[[[0.27959686 0.14511859 0.25309581]\n",
      "   [0.08025998 0.21926138 0.97625881]\n",
      "   [0.24347126 0.38751256 0.25553831]]\n",
      "\n",
      "  [[0.97385814 0.43232387 0.54145095]\n",
      "   [0.90241461 0.12008861 0.11256115]\n",
      "   [0.72047628 0.38497056 0.60125202]]\n",
      "\n",
      "  [[0.64966604 0.69502992 0.31786805]\n",
      "   [0.41165645 0.89748373 0.70215884]\n",
      "   [0.91189093 0.39660921 0.78170968]]]]\n",
      "[[[[0.14511859 0.25309581 0.68592993]\n",
      "   [0.21926138 0.97625881 0.37229464]\n",
      "   [0.38751256 0.25553831 0.34758048]]\n",
      "\n",
      "  [[0.43232387 0.54145095 0.92538702]\n",
      "   [0.12008861 0.11256115 0.25345079]\n",
      "   [0.38497056 0.60125202 0.93228833]]\n",
      "\n",
      "  [[0.69502992 0.31786805 0.28541485]\n",
      "   [0.89748373 0.70215884 0.83384668]\n",
      "   [0.39660921 0.78170968 0.75866747]]]]\n",
      "[[[[0.25309581 0.68592993 0.51459239]\n",
      "   [0.97625881 0.37229464 0.85924442]\n",
      "   [0.25553831 0.34758048 0.72266817]]\n",
      "\n",
      "  [[0.54145095 0.92538702 0.87732365]\n",
      "   [0.11256115 0.25345079 0.17000775]\n",
      "   [0.60125202 0.93228833 0.02305207]]\n",
      "\n",
      "  [[0.31786805 0.28541485 0.83468139]\n",
      "   [0.70215884 0.83384668 0.73522124]\n",
      "   [0.78170968 0.75866747 0.51453513]]]]\n",
      "[[[[0.68592993 0.51459239 0.74913671]\n",
      "   [0.37229464 0.85924442 0.11587277]\n",
      "   [0.34758048 0.72266817 0.02786164]]\n",
      "\n",
      "  [[0.92538702 0.87732365 0.86399078]\n",
      "   [0.25345079 0.17000775 0.33914352]\n",
      "   [0.93228833 0.02305207 0.58653579]]\n",
      "\n",
      "  [[0.28541485 0.83468139 0.20131367]\n",
      "   [0.83384668 0.73522124 0.0291385 ]\n",
      "   [0.75866747 0.51453513 0.96444255]]]]\n",
      "[[[[0.64084363 0.08025998 0.21926138]\n",
      "   [0.41698306 0.24347126 0.38751256]\n",
      "   [0.70182294 0.11847562 0.63335053]]\n",
      "\n",
      "  [[0.31289063 0.90241461 0.12008861]\n",
      "   [0.0584776  0.72047628 0.38497056]\n",
      "   [0.48207716 0.07732949 0.39538356]]\n",
      "\n",
      "  [[0.22661769 0.41165645 0.89748373]\n",
      "   [0.55393726 0.91189093 0.39660921]\n",
      "   [0.42297131 0.96406458 0.05640932]]]]\n",
      "[[[[0.08025998 0.21926138 0.97625881]\n",
      "   [0.24347126 0.38751256 0.25553831]\n",
      "   [0.11847562 0.63335053 0.06429769]]\n",
      "\n",
      "  [[0.90241461 0.12008861 0.11256115]\n",
      "   [0.72047628 0.38497056 0.60125202]\n",
      "   [0.07732949 0.39538356 0.99421299]]\n",
      "\n",
      "  [[0.41165645 0.89748373 0.70215884]\n",
      "   [0.91189093 0.39660921 0.78170968]\n",
      "   [0.96406458 0.05640932 0.21955537]]]]\n",
      "[[[[0.21926138 0.97625881 0.37229464]\n",
      "   [0.38751256 0.25553831 0.34758048]\n",
      "   [0.63335053 0.06429769 0.85347972]]\n",
      "\n",
      "  [[0.12008861 0.11256115 0.25345079]\n",
      "   [0.38497056 0.60125202 0.93228833]\n",
      "   [0.39538356 0.99421299 0.75546951]]\n",
      "\n",
      "  [[0.89748373 0.70215884 0.83384668]\n",
      "   [0.39660921 0.78170968 0.75866747]\n",
      "   [0.05640932 0.21955537 0.74084849]]]]\n",
      "[[[[0.97625881 0.37229464 0.85924442]\n",
      "   [0.25553831 0.34758048 0.72266817]\n",
      "   [0.06429769 0.85347972 0.07142184]]\n",
      "\n",
      "  [[0.11256115 0.25345079 0.17000775]\n",
      "   [0.60125202 0.93228833 0.02305207]\n",
      "   [0.99421299 0.75546951 0.94191243]]\n",
      "\n",
      "  [[0.70215884 0.83384668 0.73522124]\n",
      "   [0.78170968 0.75866747 0.51453513]\n",
      "   [0.21955537 0.74084849 0.72358468]]]]\n",
      "[[[[0.37229464 0.85924442 0.11587277]\n",
      "   [0.34758048 0.72266817 0.02786164]\n",
      "   [0.85347972 0.07142184 0.20966375]]\n",
      "\n",
      "  [[0.25345079 0.17000775 0.33914352]\n",
      "   [0.93228833 0.02305207 0.58653579]\n",
      "   [0.75546951 0.94191243 0.12183902]]\n",
      "\n",
      "  [[0.83384668 0.73522124 0.0291385 ]\n",
      "   [0.75866747 0.51453513 0.96444255]\n",
      "   [0.74084849 0.72358468 0.27629976]]]]\n",
      "[[[[0.41698306 0.24347126 0.38751256]\n",
      "   [0.70182294 0.11847562 0.63335053]\n",
      "   [0.83054562 0.6905831  0.36256385]]\n",
      "\n",
      "  [[0.0584776  0.72047628 0.38497056]\n",
      "   [0.48207716 0.07732949 0.39538356]\n",
      "   [0.94909898 0.36016465 0.30240884]]\n",
      "\n",
      "  [[0.55393726 0.91189093 0.39660921]\n",
      "   [0.42297131 0.96406458 0.05640932]\n",
      "   [0.75393751 0.29048194 0.08886228]]]]\n",
      "[[[[0.24347126 0.38751256 0.25553831]\n",
      "   [0.11847562 0.63335053 0.06429769]\n",
      "   [0.6905831  0.36256385 0.19063924]]\n",
      "\n",
      "  [[0.72047628 0.38497056 0.60125202]\n",
      "   [0.07732949 0.39538356 0.99421299]\n",
      "   [0.36016465 0.30240884 0.44912574]]\n",
      "\n",
      "  [[0.91189093 0.39660921 0.78170968]\n",
      "   [0.96406458 0.05640932 0.21955537]\n",
      "   [0.29048194 0.08886228 0.31349755]]]]\n",
      "[[[[0.38751256 0.25553831 0.34758048]\n",
      "   [0.63335053 0.06429769 0.85347972]\n",
      "   [0.36256385 0.19063924 0.0756697 ]]\n",
      "\n",
      "  [[0.38497056 0.60125202 0.93228833]\n",
      "   [0.39538356 0.99421299 0.75546951]\n",
      "   [0.30240884 0.44912574 0.53242787]]\n",
      "\n",
      "  [[0.39660921 0.78170968 0.75866747]\n",
      "   [0.05640932 0.21955537 0.74084849]\n",
      "   [0.08886228 0.31349755 0.36291856]]]]\n",
      "[[[[0.25553831 0.34758048 0.72266817]\n",
      "   [0.06429769 0.85347972 0.07142184]\n",
      "   [0.19063924 0.0756697  0.08807081]]\n",
      "\n",
      "  [[0.60125202 0.93228833 0.02305207]\n",
      "   [0.99421299 0.75546951 0.94191243]\n",
      "   [0.44912574 0.53242787 0.75140186]]\n",
      "\n",
      "  [[0.78170968 0.75866747 0.51453513]\n",
      "   [0.21955537 0.74084849 0.72358468]\n",
      "   [0.31349755 0.36291856 0.35881642]]]]\n",
      "[[[[0.34758048 0.72266817 0.02786164]\n",
      "   [0.85347972 0.07142184 0.20966375]\n",
      "   [0.0756697  0.08807081 0.27050627]]\n",
      "\n",
      "  [[0.93228833 0.02305207 0.58653579]\n",
      "   [0.75546951 0.94191243 0.12183902]\n",
      "   [0.53242787 0.75140186 0.05102646]]\n",
      "\n",
      "  [[0.75866747 0.51453513 0.96444255]\n",
      "   [0.74084849 0.72358468 0.27629976]\n",
      "   [0.36291856 0.35881642 0.98335932]]]]\n",
      "[[[[0.70182294 0.11847562 0.63335053]\n",
      "   [0.83054562 0.6905831  0.36256385]\n",
      "   [0.91983967 0.72428509 0.67662323]]\n",
      "\n",
      "  [[0.48207716 0.07732949 0.39538356]\n",
      "   [0.94909898 0.36016465 0.30240884]\n",
      "   [0.87303304 0.74481347 0.58477508]]\n",
      "\n",
      "  [[0.42297131 0.96406458 0.05640932]\n",
      "   [0.75393751 0.29048194 0.08886228]\n",
      "   [0.7621612  0.22919704 0.84432858]]]]\n",
      "[[[[0.11847562 0.63335053 0.06429769]\n",
      "   [0.6905831  0.36256385 0.19063924]\n",
      "   [0.72428509 0.67662323 0.97330225]]\n",
      "\n",
      "  [[0.07732949 0.39538356 0.99421299]\n",
      "   [0.36016465 0.30240884 0.44912574]\n",
      "   [0.74481347 0.58477508 0.33225119]]\n",
      "\n",
      "  [[0.96406458 0.05640932 0.21955537]\n",
      "   [0.29048194 0.08886228 0.31349755]\n",
      "   [0.22919704 0.84432858 0.36330989]]]]\n",
      "[[[[0.63335053 0.06429769 0.85347972]\n",
      "   [0.36256385 0.19063924 0.0756697 ]\n",
      "   [0.67662323 0.97330225 0.90572622]]\n",
      "\n",
      "  [[0.39538356 0.99421299 0.75546951]\n",
      "   [0.30240884 0.44912574 0.53242787]\n",
      "   [0.58477508 0.33225119 0.24544495]]\n",
      "\n",
      "  [[0.05640932 0.21955537 0.74084849]\n",
      "   [0.08886228 0.31349755 0.36291856]\n",
      "   [0.84432858 0.36330989 0.90198022]]]]\n",
      "[[[[0.06429769 0.85347972 0.07142184]\n",
      "   [0.19063924 0.0756697  0.08807081]\n",
      "   [0.97330225 0.90572622 0.44037442]]\n",
      "\n",
      "  [[0.99421299 0.75546951 0.94191243]\n",
      "   [0.44912574 0.53242787 0.75140186]\n",
      "   [0.33225119 0.24544495 0.30374117]]\n",
      "\n",
      "  [[0.21955537 0.74084849 0.72358468]\n",
      "   [0.31349755 0.36291856 0.35881642]\n",
      "   [0.36330989 0.90198022 0.9408157 ]]]]\n",
      "[[[[0.85347972 0.07142184 0.20966375]\n",
      "   [0.0756697  0.08807081 0.27050627]\n",
      "   [0.90572622 0.44037442 0.2705969 ]]\n",
      "\n",
      "  [[0.75546951 0.94191243 0.12183902]\n",
      "   [0.53242787 0.75140186 0.05102646]\n",
      "   [0.24544495 0.30374117 0.32351469]]\n",
      "\n",
      "  [[0.74084849 0.72358468 0.27629976]\n",
      "   [0.36291856 0.35881642 0.98335932]\n",
      "   [0.90198022 0.9408157  0.02209295]]]]\n"
     ]
    }
   ],
   "source": [
    "# im2col - 参数设置\n",
    "input_data = x1\n",
    "filter_h,filter_w = 5, 5\n",
    "stride, pad = 1, 0\n",
    "\n",
    "N, C, H, W = input_data.shape\n",
    "out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "for y in range(filter_h):\n",
    "    y_max = y + stride*out_h\n",
    "    for x in range(filter_w):\n",
    "        x_max = x + stride*out_w\n",
    "        col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]   # 对每个数据、通道，收集索引为(y, x)整个需要相乘的数据点\n",
    "        print(col[:, :, y, x, :, :])                                        # 例如，这里 10 x 3 x 3 x 3, 后面的3x3个数据点是5x5滤波器中的某一点在整个数据集中遍历的点\n",
    "\n",
    "col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)            # 每一行代表3x5x5的滤波器变成列与之相乘的数据点, 每3x3行代表一个数据集\n",
    "#                   数量,   通道, 滤波器长, 滤波器宽,  输出长,  输出宽 -> transpose\n",
    "#                   数量, 输出长,   输出宽,    通道, 滤波器长, 滤波器宽\n",
    "# 提示 reshape的顺序是按照0, 0, 0, 0, 0 - > 0, 0, 0, 0, 1 ... -> 0, 0, 0, 1, 0，最后一个轴是变化先变化，依次往前递进"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SimpleConvNet import im2col\n",
    "# 验证自己写的im2col正确性\n",
    "np.all(im2col(input_data, 5, 5, 1, 0) == col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.zeros(num)\n",
    "num = 3\n",
    "np.zeros(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       " \n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]]),\n",
       " array([1, 2, 3, 4]),\n",
       " array([[[ 1,  3,  5,  7],\n",
       "         [ 5,  7,  9, 11],\n",
       "         [ 9, 11, 13, 15]],\n",
       " \n",
       "        [[13, 15, 17, 19],\n",
       "         [17, 19, 21, 23],\n",
       "         [21, 23, 25, 27]]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 广播机制\n",
    "W = A\n",
    "b = np.array([1,2,3,4])\n",
    "W, b, W+b   # 最后的n个轴匹配大小才可以进行广播，顺序是从后往前进行广播\n",
    "            # b的大小: (4, )，W的大小: (2, 3, 4)，广播顺序b: (4, ) -> (3, 4) -> (2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.size\n",
    "\n",
    "A.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuple相加\n",
    "\n",
    "(1, 2) + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       " \n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23]),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten\n",
    "\n",
    "A, A.flatten(), A.reshape(-1)==A.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 28, 28), (10000, 1, 28, 28))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist_origin\n",
    "from SimpleConvNet import SimpleConvNet\n",
    "# 数据读入\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist_origin(one_hot_lable=True)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 | train_acc: 0.099 | test_acc: 0.098\n",
      "epoch  1 | train_acc: 0.924 | test_acc: 0.931\n",
      "epoch  2 | train_acc: 0.956 | test_acc: 0.959\n",
      "epoch  3 | train_acc: 0.970 | test_acc: 0.969\n",
      "epoch  4 | train_acc: 0.973 | test_acc: 0.970\n",
      "epoch  5 | train_acc: 0.978 | test_acc: 0.975\n",
      "epoch  6 | train_acc: 0.983 | test_acc: 0.978\n",
      "epoch  7 | train_acc: 0.983 | test_acc: 0.978\n",
      "epoch  8 | train_acc: 0.987 | test_acc: 0.981\n",
      "epoch  9 | train_acc: 0.989 | test_acc: 0.982\n",
      "epoch 10 | train_acc: 0.990 | test_acc: 0.983\n",
      "epoch 11 | train_acc: 0.991 | test_acc: 0.984\n",
      "epoch 12 | train_acc: 0.994 | test_acc: 0.985\n",
      "epoch 13 | train_acc: 0.993 | test_acc: 0.985\n",
      "epoch 14 | train_acc: 0.993 | test_acc: 0.986\n",
      "epoch 15 | train_acc: 0.994 | test_acc: 0.986\n",
      "epoch 16 | train_acc: 0.995 | test_acc: 0.987\n"
     ]
    }
   ],
   "source": [
    "# 网络参数\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "epoch = 0\n",
    "network = SimpleConvNet(input_dim=(1, 28, 28), \n",
    "                        conv_param={'filter_num': 5, 'filter_size':5, 'pad': 0, 'stride':1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "# 训练\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 反向传播\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    # 更新梯度\n",
    "    for key in grad.keys():\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(f\"epoch {epoch:2} | train_acc: {train_acc:.3f} | test_acc: {test_acc:.3f}\")\n",
    "        epoch += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
